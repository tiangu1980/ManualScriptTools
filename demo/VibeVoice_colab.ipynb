{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tiangu1980/ManualScriptTools/blob/main/demo/VibeVoice_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WvIaUJD2y0yU",
      "metadata": {
        "id": "WvIaUJD2y0yU"
      },
      "source": [
        "# VibeVoice Colab — T4 Quickstart (1.5B)\n",
        "\n",
        "This notebook provides a quickstart guide to run VibeVoice on Colab with T4. The T4 GPU can only support the 1.5B model due to memory limitations. Please note that T4 can only use SDPA instead of flash_attention_2, which may result in unstable and lower audio quality. For the best TTS experience, we recommend trying the 7B model on a more powerful GPU.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8fTKYGx7DZk",
      "metadata": {
        "id": "e8fTKYGx7DZk"
      },
      "source": [
        "## Step 1: Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4wxJ6QHM-ZOb",
      "metadata": {
        "id": "4wxJ6QHM-ZOb",
        "outputId": "d154313e-da3e-4f17-8320-31e68f166ca1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ T4 GPU detected\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n",
            "✅ Cloned VibeVoice repository\n",
            "\u001b[1m\u001b[31merror\u001b[39m\u001b[0m: Distribution not found at: file:///content/VibeVoice\n",
            "✅ Installed dependencies\n",
            "Cancellation requested; stopping current tasks.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/hf\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/cli/hf.py\", line 59, in main\n",
            "    service.run()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/cli/download.py\", line 132, in run\n",
            "    print(self._download())  # Print path to downloaded files\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/cli/download.py\", line 169, in _download\n",
            "    return snapshot_download(\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/_snapshot_download.py\", line 332, in snapshot_download\n",
            "    thread_map(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/contrib/concurrent.py\", line 69, in thread_map\n",
            "    return _executor_map(ThreadPoolExecutor, fn, *iterables, **tqdm_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/contrib/concurrent.py\", line 51, in _executor_map\n",
            "    return list(tqdm_class(ex.map(fn, *iterables, chunksize=chunksize), **kwargs))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/std.py\", line 1169, in __iter__\n",
            "    for obj in iterable:\n",
            "               ^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 619, in result_iterator\n",
            "    yield _result_or_cancel(fs.pop())\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 317, in _result_or_cancel\n",
            "    return fut.result(timeout)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 451, in result\n",
            "    self._condition.wait(timeout)\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 355, in wait\n",
            "    waiter.acquire()\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "✅ Downloaded model: microsoft/VibeVoice-1.5B\n"
          ]
        }
      ],
      "source": [
        "# Check for T4 GPU\n",
        "import torch\n",
        "if torch.cuda.is_available() and \"T4\" in torch.cuda.get_device_name(0):\n",
        "    print(\"✅ T4 GPU detected\")\n",
        "else:\n",
        "    print(\"\"\"\n",
        "    ⚠️ WARNING: T4 GPU not detected\n",
        "\n",
        "    The recommended runtime for this Colab notebook is \"T4 GPU\".\n",
        "\n",
        "    To change the runtime type:\n",
        "\n",
        "        1. Click on \"Runtime\" in the top navigation menu\n",
        "        2. Click on \"Change runtime type\"\n",
        "        3. Select \"T4 GPU\"\n",
        "        4. Click \"OK\" if a \"Disconnect and delete runtime\" window appears\n",
        "        5. Click on \"Save\"\n",
        "\n",
        "    \"\"\")\n",
        "\n",
        "# Clone the VibeVoice repository\n",
        "![ -d /content/VibeVoice ] || git clone --quiet --branch main --depth 1 https://github.com/great-wind/MicroSoft_VibeVoice.git /content/VibeVoice\n",
        "print(\"✅ Cloned VibeVoice repository\")\n",
        "\n",
        "# Install project dependencies\n",
        "!uv pip --quiet install --system -e /content/VibeVoice\n",
        "print(\"✅ Installed dependencies\")\n",
        "\n",
        "# Download model (~3 minutes)\n",
        "!HF_XET_HIGH_PERFORMANCE=1 hf download microsoft/VibeVoice-1.5B --quiet  --local-dir /content/models/VibeVoice-1.5B > /dev/null\n",
        "print(\"✅ Downloaded model: microsoft/VibeVoice-1.5B\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pgKlV7153Ifi",
      "metadata": {
        "id": "pgKlV7153Ifi"
      },
      "source": [
        "## Step 2: Create Transcript"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Yc1N9EHswFxA",
      "metadata": {
        "id": "Yc1N9EHswFxA"
      },
      "outputs": [],
      "source": [
        "%%writefile /content/my_transcript.txt\n",
        "Speaker 1: Can I try VibeVoice with my own example?\n",
        "Speaker 2: Of course! VibeVoice is open-source, built to benefit everyone - you're welcome to try it out.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MBCC6s-F6_hP",
      "metadata": {
        "id": "MBCC6s-F6_hP"
      },
      "source": [
        "## Step 3: Generate Audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dYWsLJ-n0Npm",
      "metadata": {
        "id": "dYWsLJ-n0Npm"
      },
      "outputs": [],
      "source": [
        "# Run Python script to generate audio from transcript\n",
        "!python /content/VibeVoice/demo/inference_from_file.py \\\n",
        "    --model_path /content/models/VibeVoice-1.5B \\\n",
        "    --txt_path /content/my_transcript.txt \\\n",
        "    --speaker_names Alice Frank\n",
        "\n",
        "# Display audio controls\n",
        "from IPython.display import Audio\n",
        "Audio(\"/content/outputs/my_transcript_generated.wav\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec6438d5",
      "metadata": {
        "id": "ec6438d5"
      },
      "source": [
        "# Step 4: Download Audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b40ffa22",
      "metadata": {
        "id": "b40ffa22"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/outputs/my_transcript_generated.wav\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bce752d",
      "metadata": {
        "id": "1bce752d"
      },
      "source": [
        "\n",
        "## Risks and Limitations\n",
        "\n",
        "While efforts have been made to optimize it through various techniques, it may still produce outputs that are unexpected, biased, or inaccurate. VibeVoice inherits any biases, errors, or omissions produced by its base model (specifically, Qwen2.5 1.5b in this release). Potential for Deepfakes and Disinformation: High-quality synthetic speech can be misused to create convincing fake audio content for impersonation, fraud, or spreading disinformation. Users must ensure transcripts are reliable, check content accuracy, and avoid using generated content in misleading ways. Users are expected to use the generated content and to deploy the models in a lawful manner, in full compliance with all applicable laws and regulations in the relevant jurisdictions. It is best practice to disclose the use of AI when sharing AI-generated content."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "name": "VibeVoice_Colab.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}